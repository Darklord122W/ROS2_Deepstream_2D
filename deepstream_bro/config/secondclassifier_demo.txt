[property]
is-classifier=1
classifier-async-mode=0
gpu-id=0
operate-on-gie-id=1
# SGIE must have a different unique id than PGIE
gie-unique-id=2

# THIS makes it a secondary inference
process-mode=2
network-type=1              # classifier

# Tell SGIE which upstream GIE to use (your detector is 1)
operate-on-gie-id=1

# THIS controls which detector classes will be cropped+classified
# Put your desired YOLO class IDs here (example: 41=cup in COCO)
# operate-on-class-ids=39;41

# Batch size = max objects you expect per frame (not camera batch)
batch-size=16

interval=0                  # classify every frame; raise to skip frames

# Model
# onnx-file=/home/autodrive/justperception/src/deepstream_bro/config/terminalbatch1imgsz224.onnx
# model-engine-file=yolo26n-clsbatch16.onnx_b16_gpu0_fp32.engine
# model-engine-file=yolo26n-clsbatch16.onnx_b16_gpu0_fp32.engine
# model-engine-file=yolo26n-cls.onnx_b1_gpu0_fp32.engine
model-engine-file=terminalbatch1imgsz224.onnx_b16_gpu0_fp32.engine
labelfile-path=/home/autodrive/justperception/install/deepstream_bro/share/deepstream_bro/config/labels_imagenet_1k.txt

net-scale-factor=0.003921568627
model-color-format=0

# Set infer-dims to the classifier input size
# If your classifier expects 224x224:
# infer-dims=3;224;224

# For debugging only; not required in production
output-tensor-meta=0


input-object-min-width=0
input-object-min-height=0
classifier-threshold=0.4
